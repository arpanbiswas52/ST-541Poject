---
title: "An  approach to Robust Optimization of Large Scale Complex River System"
author: "Arpan Biswas"
output:
  pdf_document
---

# Introduction 

Renewable energy, such as hydroenergy, is one of the major sources for electricity generation for energy sectors. Over many decades, there has been continuous development of water resource management for the economic benefit of electricity industries. However, in real world, these energy sectors deal with different sources of uncertainties like Inflows, Market Prices and Market Demand of electricity which significantly impacts their operations and therefore in generating revenue. Therefore, the objective in this project is to generate a Robust Optimization framework for maximizing the Net Revenue and thereby provide a robust solution of optimal operation control. However, RO model is generally too expensive due to its high simulation and function evaluation costs during quantification and propagation of uncertainty through the large scale complex system. This can make the model inefficient since the operators need to run the model at regular interval of time (hourly). Therefore, in this project, another research objective is to investigate on increasing the efficiency of the model in terms of reducing computational cost and/or providing better robust optimal solutions.

# Model Description

In this section, we have presented the Robust optimization model and have discussed the efforts done to build the model. In this problem, we have selected our decision variables as Outflows from the reservoirs and objective function is maximizing Expected Revenue. The problem includes constraints on Storage, Forebay elevation, Power output and Forebay elevation at end of period. The model starts with inputting Inflows, Price and decision variables as Outflows. After that, large scale simulations of Storage, Forebay, Tailwater, Head, Energy generation and Revenue is executed and the respective means and standard deviations is calculated. After that, the model calculates Robust objective function and validates all the Probabilistic constraints with Reliability index of $0.9$ or $90$%. The model then checks if the convergence criteria and no constraints violation have been achieved. If satisfied, the model provides the optimal solution as Outflows and Expected Revenue. If not, the model moves to next iteration and start the simulations again with different sets of decision variables. 

# Methodology

In this section, we have discussed about the methodology applied in RO model. Firstly, we have applied Monte Carlo simulations methods to execute the large complex simulations at each iteration of the optimization. The robust optimization model has been built in R using package "nloptr" and applying Sequential Quadratic Programing algorithm. This gradient based algorithm is very efficient in any non-linear optimization problems. Though it provides generally a local optimal solution, it quickly converges to a solution. In R, the function needed to call SQP algorithm is "slsqp". However, there is a caveat in "slsqp" as it has restriction to input any arguments other than decision variables to the constraint function provided by the user into the algorithm. We believe this is a bug and in order to complete the project, we had to rewrite all the inputs and initial conditions again inside the constraint function. Due to these limitations, the coding might look repetitive in the constraint function. In this project, the convergence criteria is the step size of decision variables $< 1e-10$. Since one of our prime focus is the computational efficiency of the model, we have always attempted to code the RO model efficiently by extensive applications of operations of large data in vectors and matrices, using `rowMeans()`, `colMeans()` etc., building several small functions to avoid redundant execution of codes multiple times, avoiding loops in large simulations. However, we had to use loops in calculating some quantities like Storage in each days (timesteps) since we need to know the value of storage at pervious day to calculate the storage at the current day. Therefore, calculating the value of storage of 14 days together was not possible using operations in vectors. However, this will not significantly increase the runtime as we need to calculate for 14 days only (14 iterations). 

# Analysis on increasing Computational Efficiency and accuracy in estimations 

In this section, we have mentioned about the analysis done on the RO model to increase the efficiency of the model. As we mentioned, MC approach has been taken initially to perform the simulations. However, MC approach is computationally inefficient. This could increase the computational cost of the model significantly and therefore we have attempted Antithetic Variable approach. Antithetic variable approach can reduce the variance and provide better estimations and also required less sampling which can increase the overall computational efficiency of the model. Therefore, we have compared the performance of RO model using MC approach and Antithetic variable approach. We also went further to compare with Important Sampling approach. However, it turned out to be too complex to code in our problem and due to the time constraint to complete the project we have decided to consider this as a future task.

# Results

In this section, we have provided the description of the case study with all the results from the model and model comparisons. In this case study, we have considered 3 reservoirs (Grand Coulee, Lower Granite and McNaire) from Lower Columbia River System where there are two inflow channels: Inflows to Grand Coulee (GCL) and inflows to Lower Granite (LWG). The inflows to McNaire (MCN) are the total outflows from Grand Coulee and Lower Granite reservoirs. The optimization period has been considered as 14 days with daily timesteps. In this case study, we have 42 decision variables and 250 constraints validation. Historical inflows data has been considered of GCL and LWG to predict the inflows for two weeks period (Figure 1, 2 respectively). From the means and standard deviations of these historical data, 500 samples (considering normal distribution) of each inflows at each day have been taken for MC approach. We have generated few predicted data of prices based on the range provided by BPA (Bonneville Power Administration). From the mean and the standard deviation of Price data (Figure 3), we need to generate $500*500 = 250000$ samples (considering Normal distribution). This is because in order to simulate the revenue each day, total energy generated each day from two sources of inflows has been simulated with all possible realizations $500*500$. Figure 4 shows the optimal outflows from the three reservoirs using MC approach. We can observe that the optimal decision is to release more water (higher outflow values) to generate more energy and on the day with higher predicted mean price and lower standard deviations like on day 3, 10 and 12, thereby generating more expected revenue. Thus we get a robust decision. The estimated total revenue during 14 days optimization period is 88 million dollars approx.  Next, we have applied antithetic variable approach with 100 samples of each inflows at each day, therefore generated $100*100 = 10000$ samples for price. To check the performance of the Antithetic variable approach in our problem in reducing the variance, we have compared the variances of storage of GCL and LWH with that in MC approach. Figure 5 shows the reduction of variances using Antithetic approach which is quite significant. Due to the reduction of variances in the estimation of quantities of interest in future days, we get a better estimated revenue of 88.9 million dollars at the optimal solution from the model. There, we observe an improvement in revenue of 0.9 million dollars (1%). Also, with lesser number of simulations, each iteration took $4.64s$ approx. with total runtime (106 iterations) of $8 mins$ approx. whereas each iteration for MC approach took $128s$ approx. with total runtime (9 iterations) of $19 mins$ approx. Figure 6 shows the optimal outflows from the three reservoirs using Antithetic variable approach. The optimal decision still provides higher outflows (day 3, 10 and 12) among the other days due to relatively higher mean prices with lower standard deviations, thereby ensuring the robustness of the solution is still intact. 


```{r,warning=FALSE, message= FALSE, echo=FALSE}
##![](results/estimated\ price.png)
library(readr)
t<-14
par(mfrow=c(2,2))

GCLInflowsdata <- read_csv("data/GCLInflowsdata.csv")
GCLInflows<- GCLInflowsdata[-c(1)]
plot(c(1:t), t(GCLInflows[ ,1]),type = "o", col="blue", pch="o", lty=1, ylim =c(60,90), xlab="day",ylab = "Inflows (kcfs)", main = "Fig 1. Inflows of GCL", prob=TRUE, cex.main = 0.75,cex.lab = 0.75)
for (i in 2:(length(GCLInflows))){
lines(c(1:t), t(GCLInflows[,i]), type = "o", col="blue", pch="o", lty=1)
}

LWGInflowsdata <- read_csv("data/LWGInflowsdata.csv")
LWGInflows<- LWGInflowsdata[-c(1)]
plot(c(1:t), t(LWGInflows[ ,1]),type = "o", col="red", pch="*", lty=1, ylim =c(10,30), xlab="day",ylab = "Inflows (kcfs)", main = "Fig 2. Inflows of LWG", prob=TRUE, cex.main = 0.75,cex.lab = 0.75)
for (i in 2:(length(LWGInflows))){
lines(c(1:t), t(LWGInflows[,i]), type = "o", col="red", pch="*", lty=1)
}

par(mfrow=c(2,2))
Pricedata <- read_csv("data/Pricedata.csv")
Pricedata_Mean <- colMeans((Pricedata[,2:15]))
Pricedata_Mean2 <- colMeans((Pricedata[,2:15])^2)
Pricedata_sd <- sqrt(Pricedata_Mean2 - Pricedata_Mean^2)
plot(c(1:t), Pricedata_Mean,type = "o", col="blue", pch="o", lty=1, ylim =c(0,100), xlab="day",ylab = "Price/ MWh", main = "Fig 3. Predicted Price", prob=TRUE, cex.main = 0.75,cex.lab = 0.75)
lines(c(1:t), (Pricedata_Mean+ 1*Pricedata_sd), type = "o", col="red", pch="*", lty=2)
lines(c(1:t), (Pricedata_Mean- 1*Pricedata_sd), type = "o", col="red", pch="*", lty=2)
legend(1,100,legend=c("Means","+-1 std devs"), col=c("blue","red"),pch=c("o","*"), lty=c(1,2),cex = 0.5)

opt_Q_MC <- readRDS("Results/optoutflows_MC.rds")
plot(c(1:t), opt_Q_MC[1,],type = "o", col="blue", pch="o", lty=1, ylim =c(0,500), xlab="day",ylab = "Outflows (kcfs)", main = "Fig 4.Optimal Outflows (MC approach)", prob=TRUE, cex.main = 0.75,cex.lab = 0.75)
lines(c(1:t), opt_Q_MC[2,], type = "o", col="red", pch="*", lty=2)
lines(c(1:t), opt_Q_MC[3,], type = "o", col="black", pch="+", lty=3)
legend(6,500,legend=c("GCL","LWG", "MCN"), col=c("blue","red","black"),pch=c("o","*","+"), lty=c(1,2,3),cex = 0.45)

var_red <- readRDS("Results/variance_reduction_data.rds")
plot(c(1:t), var_red[1,],type = "o", col="blue", pch="o", lty=1, ylim =c(0,500), xlab="day",ylab = "Variance reduction (kcfs-day)", main = "Fig 5. Variance reduction by Antithetic approach", prob=TRUE, cex.main = 0.75,cex.lab = 0.75)
lines(c(1:t), var_red[2,], type = "o", col="red", pch="*", lty=2)
legend(1,500,legend=c("GCL-Storage","LWG-Storage"), col=c("blue","red"),pch=c("o","*"), lty=c(1,2),cex = 0.75)

opt_Q_AV <- readRDS("Results/optoutflows_antithetic.rds")
plot(c(1:t), opt_Q_AV[1,],type = "o", col="blue", pch="o", lty=1, ylim =c(0,500), xlab="day",ylab = "Outflows (kcfs)", main = "Fig 6.Optimal Outflows (Antithetic Variable approach)", prob=TRUE, cex.main = 0.75,cex.lab = 0.75)
lines(c(1:t), opt_Q_AV[2,], type = "o", col="red", pch="*", lty=2)
lines(c(1:t), opt_Q_AV[3,], type = "o", col="black", pch="+", lty=3)
legend(6,500,legend=c("GCL","LWG", "MCN"), col=c("blue","red","black"),pch=c("o","*","+"), lty=c(1,2,3),cex = 0.45)


```

# Conclusion

We will now conclude the project with some final thoughts. This approach of robust optimization in quantifying uncertainty and providing robust decisions is very significant in real world problems which is not only restricted to energy problems. Therefore, the framework can be applicable to any early design problems when the uncertainty is generally higher. Also, the real problems are generally large scale complex problem and therefore computational efficiency is a key factor. In this project, we could see that an efficient sampling method can help in better representation of future uncertainties and minimize the variance of the estimation which can lead to better optimal robust decisions. With efficient sampling, we can also confidently consider lesser simulations and still have the efficiency in terms of accuracy.
